# 4. Hadoop HDFS

Hadoop文件系统使用分布式文件系统设计开发。不像其他的分布式系统，它运行在普通硬件。

HDFS是高度容错以及使用低成本的硬件设计的文件系统。

HDFS拥有超大型的数据量，并提供了更轻松的访问。为了存储这些庞大的数据，这些文件都存储在多台机器上。这些文件的存储是以冗余的方式来保护系统在发生故障时免受可能的数据丢失。HDFS也可以并行处理应用程序。

#### HDFS的特点

- 它适用于分布式存储和处理。
- Hadoop提供的命令接口与HDFS进行交互。
- 名称节点（namenode）和数据节点（datanode）帮助用户通过内置的服务器轻松检查集群的状态。
- 流式访问文件系统数据。
- HDFS提供了文件的权限和验证。

#### HDFS架构

Hadoop文件系统的体系结构如图：

![image-20200615113835324](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615113835.png)

HDFS遵循主从架构，它具有以下元素：

##### 名称节点 - Namenode

名称节点是包含GNU/Linux操作系统和软件名称节点的普通硬件。它是一个可以在商业硬件上运行的软件。

具有名称节点的系统作为主服务器。它执行以下任务：

- 管理文件系统命名空间。
- 规范客户端对文件的访问。
- 它也执行文件系统操作。如重命名，关闭和打开文件和目录。

##### 数据节点 - Datanode

Datanode是具有GNU/Linux操作系统和软件Datanode的普通硬件。对于集群中的每个节点（普通硬件/系统），有一个数据节点。这些节点管理数据并存储在它们的系统。

- 数据节点上的文件系统根据用户请求执行读写操作。
- 还可以根据名称节点的指令执行操作，如块的创建，删除和复制。

#### 块

一般用户数据存储在HDFS文件系统。

在一个文件系统中的文件被划分为一个或多个段和/或存储在个人数据的节点。这些文件段被称为块。

也就是说数据的HDFS可以读取或写入的最小量被称为一个块。缺省的块大小为64MB，这可以按需根据HDFS配置来改变。

#### HDFS的目标

- 故障检测和恢复：由于HDFS包括大量的普通硬件，部件故障频繁。因此HDFS应该具有快速和自动的故障检测和恢复机制。
- 巨大的数据集：HDFS有数百个集群节点来管理其庞大的数据集的应用程序。
- 数据硬件：请求的任务当计算发生不久后可以高效的完成。HDFS涉及到巨大的数据集，它需要减少网络通信量，增加吞吐量。

