# 3. Hadoop是什么

Hadoop是使用Java编写的、允许分布在集群、使用简单的编程模型的计算机处理大型数据集的Apache开源框架。

Hadoop框架应用了工程提供的跨计算机集群的分布式存储和计算的环境，是专为从单一服务器扩展到上千台服务器、让每个机器都可以提供本地计算和存储的框架。

#### Hadoop的架构

在其核心，Hadoop主要有两个层次，即：

- 加工/计算层（MapReduce）
- 存储层（Hadoop分布式文件系统）

![image-20200615110250391](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615110250.png)

#### MapReduce

MapReduce是一种并行编程模型，用于编写普通硬件的设计，谷歌对大量数据的高效处理（多TB数据集）的分布式应用在大型集群（数千个节点）以及可靠的容错方式。

MapReduce程序可在Apache的开源框架Hadoop上运行。

#### Hadoop分布式文件系统

Hadoop分布式文件系统（HDFS）基于谷歌文件系统（GFS），并提供了一个设计在普通硬件上运行的分布式文件系统。它与现有的分布式文件系统有许多相似之处。它高度容错并设计成部署在低成本的硬件上。

HDFS提供了高吞吐量的应用数据访问，并适用于具有大数据集的应用程序。

除了上面提到的两个核心组件，Hadoop框架还包括以下两个模块：

- Hadoop通用工具(Common Utilities）：Java库和其他的Hadoop组件所需要的实用工具。
- Hadoop YARN：这是作业调度和集群资源管理的框架。

#### Hadoop如何工作？

建立重新配置、处理大规模数据的服务器是相当昂贵的。

作为替代，可以联系许多采用单CPU的普通电脑在一起，作为一个单一功能的分布式系统。

实际上，集群的机器可以并行地获取数据集，并提供一个高得多的吞吐量。此外，这样比一个高端服务器的价格更便宜，因此使用Hadoop跨集群在低成本上的机器上运行是一个不错的选择。

Hadoop运行整个计算机集群的代码。这个过程包括以下核心任务由Hadoop执行：

- 数据最初分为目录和文件。文件分为64M和128M（最好用128M）统一大小块。
- 然后这些文件被分布在不同的集群节点，以便进一步处理。
- HDFS在本地文件系统的顶端监督处理。
- 块复制处理硬件故障。
- 检查代码是否已成功执行。
- 执行发生映射之间，减少阶段的排序。
- 发送排序的数据到某一个计算机。
- 为每个作业编写调试日志。

#### Hadoop的优势

- Hadoop框架允许用户快速编写和测试分布式系统。有效地在整个集群上自动分配数据和工作，充分利用CPU内核的基本并行度。
- Hadoop不依赖硬件，提供容错和高可用性（fault tolerance and high availability, FTHA），Hadoop库本身已被设计在应用层，可以检测和处理故障。
- 服务器可以添加或从集群动态删除，Hadoop可继续不中断地运行。
- Hadoop是开源的的，它基于Java并兼容所有的平台。