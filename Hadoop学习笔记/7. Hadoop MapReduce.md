# 7. Hadoop MapReduce

MapReduce是一个可以在普通硬件的大集群上编写应用程序以并行、可靠的方式处理海量数据的框架。

#### MapReduce是什么？

MapReduce是一种处理技术和程序模型的基于Java的分布式计算框架。

MapReduce算法包含了两项重要任务，即Map和Reduce。

Map采用了一组数据并将其转换成另一组数据，其中各个元件被分解成元祖（键/值对）。其次，减少任务，这需要从Map作为输入并组合那些数据元组成的一组小的元祖输出。

在Map作业之后执行reduce任务。

MapReduce的主要优点是，它很容易在多个计算节点处理大规模数据。下面的MapReduce模型中数据处理的原语被称为映射器和减速器。分解数据处理应用到映射器和减速器没什么大不了的，但要编写MapReduce形式的应用，扩展应用程序运行在几百，几千甚至几万集群中而仅仅通过一个配置的更改这种简单的可扩展性才是吸引众多程序员使用MR模型的原因。

#### 算法

通常MapReduce范例是基于发送数据的计算机的位置。

MapReduce计划分三个阶段执行，即映射阶段(map), shuffle阶段，减少阶段(reduce)。

- 映射阶段：映射或映射器的工作是处理输入数据。一般输入数据是文件或目录的形式，并且被存储在Hadoop的文件系统（HDFS）。输入文件被传递到有限的映射器，映射器处理该数据，并创建数据的若干小块。
- 减少阶段：这个阶段是Shuffle阶段和Reduce阶段的组合。减速器的工作是处理来自映射器中的数据。处理之后，它产生一组新的输出，存储在HDFS。

在一个MapReduce工作中，Hadoop发送Map和Reduce任务到集群的相应服务器。

框架管理数据传递，例如发出任务的所有节点之间的集群周围的详细信息，验证任务完成和复制数据。

大部分的计算发生在本地磁盘上，可以减少网络通信量。

给定任务完成后，将收集集群并减少数据，以形成一个合适的结果，并且将其发送回Hadoop服务器。

![image-20200615141043783](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615153527.png)

#### 输入和输出（Java透视图）

MapReduce框架上对<key, value>对进行操作，也就是说框架视图中输入需要一组<key, value<对，并产生一组<key, value>对作为作业的输出。

需要实现接口。键类必须实现可写，可比（较）接口，以方便框架排序。

MapReduce工作的输入和输出类型：

（输入）<k1, v1> -> 映射 -> <k2, v2> -> reduce -> <k3, v3>（输出）

|        |      输入      |      输出      |
| :----: | :------------: | :------------: |
|  Map   |    <k1, v1>    | list(<k2, v2>) |
| Reduce | <k2, list(v2)> | list(<k3, v3>) |

#### 术语

- PayLoad：应用程序实现映射和减少功能，形成工作的核心。
- Mapper：映射器的输入键/值对映射到一组中间键/值对。
- NameNode：节点管理Hadoop分布式文件系统（HDFS）。
- DataNode：在任何处理发生之前呈现节点数据。
- MasterNode：节点所在JobTracker运行并接受来自客户端作业请求。
- SlaveNode：节点所在Map和Reduce程序运行在slave节点。
- JobTracker：调度作业并跟踪作业分配给任务跟踪器。
- Task Tracker：跟踪任务和报告状态的JobTracker。
- Job：程序在整个数据集映射和减速的执行。
- Task：一个映射程序的执行或对数据的一个片段的减速器。
- Task Attempt：一种特定实例在SlaveNode执行任务的尝试。

#### 重要命令

所有的Hadoop命令都是由$HADOOP_HOME/bin/hadoop命令调用。

Usage: hadoop [--config confdir] COMMAND

下面列出了可用的选项以及说明。

|             操作             |                      描述                      |
| :--------------------------: | :--------------------------------------------: |
|       namenode -format       |              格式化DFS文件系统。               |
|      secondarynamenode       |             运行DFS二次名称文件。              |
|           namenode           |               运行DFS名称节点。                |
|           datanode           |              运行DFS的Datanode。               |
|           dfsadmin           |              运行DFS管理客户端。               |
|           mradmin            |           运行映射，减少管理客户端。           |
|             fsck             |           运行DFS文件系统检查工具。            |
|              fs              |      运行一个通用的文件系统的用户客户端。      |
|           balancer           |               运行集群平衡工具。               |
|             oiv              |       适用于离线Fslmage查看器的fsimage。       |
|           fetchdt            |             从NameNode获取团令牌。             |
|          jobtracker          |          运行MapReduce工作跟踪节点。           |
|            pipes             |                运行管道的工作。                |
|         tasktracker          |          运行MapReduce任务跟踪节点。           |
|        historyserver         | 运行作业历史记录服务器作为一个独立的守护进程。 |
|             job              |              操纵MapReduce工作。               |
|            queue             |             获取有关作业队列信息。             |
|           version            |                   打印版本。                   |
|          jar <jar>           |               运行一个jar文件。                |
|  distcp <srcurl> <desturl>   |              递归复制文件或目录。              |
| archive -archiveName NAME -p |             创建一个Hadoop的归档。             |
|          classpath           |  打印需要得到Hadoop jar和所需要的库的类路径。  |
|          daemonlog           |       为每个守护进程获取/设置日志级别。        |

#### 如何与MapReduce工作互动

Usage： hadoop job [GENERIC_OPTIONS]

一下是在一个Hadoop的作业的可用通用选项。

|               GENERIC_OPTIONS                |                             描述                             |
| :------------------------------------------: | :----------------------------------------------------------: |
|              -submit <job-file>              |                          提交作业。                          |
|               status <job-id>                |     打印映射，并减少完成的百分比以及所有的工作的计数器。     |
| counter <job-id>  <group-name> <countername> |                       打印的计数器值。                       |
| -events <job-id> <fromevent-#> <#-of-events> |      打印接收到JobTracker为给定范围内的事件的详细信息。      |
|        -history [all] <jobOutputDir>         | 打印作业的详细信息，作业未能终止时提供详细的信息。有关作业的更多详细信息，如每个成功的任务，可以尝试通过制定[all]选项查看。 |
|                  -list[all]                  |          显示所有作业。-list只显示尚未完成的作业。           |
|             -kill-task <task-id>             |             终止任务。终止任务不计入失败的尝试。             |
|             -fail-task <task-id>             |                         失败的任务。                         |
|       set-priority <job-id> <priority>       | 更改作业的优先级。允许设置的优先级有：VERY_HIGH, HIGH, NORMAL, LOW, VERY_LOW |

##### 查看作业的状态

> $ $HADOOP_HOME/bin/hadoop job -status <job-id>
>
> $ $HADOOP_HOME/bin/hadoop job -status job_20200615666_0001

##### 在output-dir查看作业历史

> $ $HADOOP_HOME/bin/hadoop job -history <dir-name>
>
> $ $HADOOP_HOME/bin/hadoop job -history /user/expert/output

##### 终止任务

> $ $HADOOP_HOME/bin/hadoop job -kill <job-id>
>
> $ $HADOOP_HOME/bin/hadoop job -kill job_20200615666_0001