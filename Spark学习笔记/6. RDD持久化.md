# 6. RDD持久化

Spark通过在操作中将数据持久保存在内存中，提供了一种处理数据集的便捷方式。

在持久化RDD的同时，每个节点都存储它在内存中计算的任何分区，也可以在该数据集的其他任务中重用他们。

可以使用`persist()`或`cache(0)`方法来标记要保留的RDD。Spark的缓存是容错的。在任何情况下，如果RDD的分区丢失，spark将使用最初创建它的`转换`自动重新计算。

存在可用于存储持久RDD的不同存储级别。通过将`StorageLevel`对象（Scala，java，python）传递给`persist()`来使用这些级别。`cache()`方法用于默认存储级别，即`StorageLevel.MEMORY_ONLY`。

存储级别的集合：

|               存储级别               |                             描述                             |
| :----------------------------------: | :----------------------------------------------------------: |
|            `MEMORY_ONLY`             | 将RDD存储为JVM中的反序列化Java对象。这是默认级别。如果RDD不适合内存，则每次需要时都不会缓存和重新计算某些分区。 |
|          `MEMORY_ADD_DISK`           | 它将RDD存储为JVM中反序列化Java对象。如果RDD不适合内存，请存储在适合磁盘的分区，并在需要时从磁盘读取它们。 |
|          `MEMORY_ONLY_SER`           | 它将RDD存储为序列化Java对象（即每个分区一个字节的数组）。这通常比反序列对象更节省空间。 |
|        `MEMORY_ADD_DISK_SER`         | 类似于`MEMORY_DISK_SER`，但是将内存中不适合的分区溢出到磁盘而不是重新计算它们。 |
|             `DISK_ONLY`              |                 它仅将RDD分区存储在磁盘上。                  |
| `MEMORY_ONLY_2`, `MEMORY_AND_DISK_2` |       它与上面的级别相同，但复制两个集群上的每个分区。       |
|              `OFF_HEAP`              | 类似于`MEMORY_ONLY_SER`，但将数据存储在堆外内存中。必须启用堆外内存。 |

