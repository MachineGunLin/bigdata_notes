# 2.Spark架构

Spark遵循主从架构。Spark集群由一个主服务器和多个从服务器组成。

Spark架构依赖于两个抽象：

1. ​	弹性分布式数据集（RDD）
2. ​    有向无环图（DAG）

#### 弹性分布式数据集（RDD）

弹性分布式数据集就是可以存储在工作节点上的内存中的数据项组。

- 弹性： 失败时恢复数据
- 分布式： 数据分布在不同的节点之间
- 数据集： 数据组

#### 有向无环图（DAG）

有向无环图对数据执行一系列计算。每个节点都是RDD分区，边缘是数据顶部的转换。

### Spark架构图

![image-20200611153954186](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200611154003.png)

#### 驱动程序 Driver Program

驱动程序是一个运行应用程序，由`main（）`函数创建`SparkContext`对象的进程。

`SparkContext`的目的是协调spark应用程序，作为集群上的独立进程集运行。

要在集群上运行，`SparkContext`要连接到不同类型的集群管理器，然后执行以下任务：

- 在集群的节点上获取执行程序
- 将应用程序代码发送给执行程序。应用程序代码可以通过传递给`SparkContext`的JAR或者Python文件来定义
- 最后，`SparkContext`将任务发送给执行程序以运行

#### 集群管理器 Cluster Manager

Spark能够在大量集群上运行需要集群管理器，集群管理器的作用就是跨应用程序分配资源。它由各种类型的集群管理器组成，例如：`Hadoop Yarn`，`Apache Mesos`和`Standalone scheduler`。

这里standalone scheduler是一个独立的Spark集群管理器，便于在一组空机器上安装Spark。

#### 工作节点 Worker Node

工作节点是从节点。它的作用是在集群中运行应用程序代码。也就是实际上干活的。

#### 执行程序 Executor

- 执行程序是为工作节点上的应用程序启动的进程
- 执行程序运行任务并将数据保存在内存或者磁盘存储中
- 它将数据读写到外部源
- 每个应用程序都包含其执行者(Executor)

#### 任务 Task

任务被发送给一个执行程序的工作单位

