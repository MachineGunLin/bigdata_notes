# 4.弹性分布式数据集（RDD）简介

***弹性分布式数据集（RDD）是Spark的核心抽象之一。它是一组元素，在集群的节点之间进行分区，以便我们可以对其执行各种并行操作。***

创建RDD有两种方法：

1. 并行化驱动程序中的现有数据。
2. 引用外部存储系统中的数据集。例如：共享文件系统、HDFS、HBASE或者提供Hadoop InputFormat的数据源。

#### 1.并行化集合

要创建并行化集合，在驱动程序的现有集合上调用`SparkContext`的`parallelize`方法。

复制集合中的每个元素以形成可并行操作的分布式数据集。

```
var info = Array(1, 2, 3, 4)
var distinfo = sc.parallelize(info)
```

现在，可以操作分布式数据集distinfo，例如`distinfo.reduce((a, b) => a + b)`

#### 2.外部数据集

在Spark中，可以从Hadoop支持的任何类型的存储源（如HDFS，Cassandra, HBase甚至本地文件系统）创建分布式数据集。Spark提供对文本文件，`SqeuenceFiles`和其他类型的Hadoop InputFormat的支持。

`SparkContext`的`textFile`方法可用于创建RDD的文本文件。此方法获取文件的URL（计算机上的本地路径或`hdfs://`)并读取文件的数据。



可以通过数据集来操作数据。例如使用`map`和`reduceoperations`来添加所有行的大小：`data.map(s => s.length).reduce((a, b) => a + b)`