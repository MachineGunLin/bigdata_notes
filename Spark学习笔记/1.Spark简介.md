# 1.Spark简介

Apache Spark是一个开源集群计算框架，主要目的是处理实时生成的数据。

Spark与hadoop的MapReduce等替代方案将数据写入计算机硬盘驱动器或从计算机硬盘驱动器写入数据不同，它被优化为在内存中运行。**因此spark比其他替代方案能更快地处理数据。**

#### Spark的功能

1. 快速(Speed)：Spark采用最先进的DAG（有向无环图）调度程序，查询优化器和物理执行引擎，为批处理和流数据提供高性能。
2. 易于使用(Ease of Use)： Spark可以使用Java、Scala、Python、R和SQL编写应用程序。另外它还提供80多个高级运算符。
3. 通用性(Generality)：Spark提供了一系列库，包括SQL和DataFrames，机器学习库MLLib，GraphX和Spark Streaming。
4. 轻量级：Spark是一种轻量级的统一分析引擎，用于大规模数据处理。
5. 无处不在(Runs Everywhere)： Spark可以运行在Hadoop、Apache Mesos、Kubernetes，独立（standalone）或者云端。

#### Spark的使用场景

1. 数据集成： 系统生成的数据不够整合，无法结合进行分析。要从系统中获取一致的数据。可以使用提取，转换和加载（ETL）等过程。Spark可用于减少此ETL过程所需的成本和时间。
2. 流处理： Spark可以运行数据流处理实时生成的数据（如日志文件），并拒绝潜在的欺诈性操作。
3. 机器学习： 由于数据量的增加，机器学习方法变得更加可行并且越来越准确。Spark可以将数据存储在内存中并且可以快速运行重复查询，因此可以轻松处理机器学习算法。
4. 交互式分析： Spark能够快速生成相应，因此可以交互式地处理数据，而不是运行预定义的查询。