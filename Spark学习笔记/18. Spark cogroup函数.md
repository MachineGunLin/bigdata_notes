# 18. Spark cogroup函数

在Spark中，`cogroup`函数对不同的数据集执行分组操作，比如，对(K, V)和(K, W)执行cogroup并返回`(K, (Iterable, Iterable))`元祖的数据集。此操作也称为`groupWith`。

#### cogroup函数示例

使用并行化集合创建RDD：

> scala> val data1 =  sc.parallelize(Seq(("A", 1), ("B", 2), ("C", 3)))

读取生成的结果：

> scala> data1.collect

![image-20200612111743297](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612111743.png)

使用并行化集合创建另一个RDD：

> scala> val data2 = sc.parallelize(Seq(("B", 4), ("E", 5)))

读取生成的结果：

> scala> data2.collect

![image-20200612111949225](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612111949.png)

使用`cogroup()`函数对值进行分组：

> scala> val cogroupfunc = data1.cogroup(data2)

读取生成的结果：

> scala> cogroupfunc.collect

![image-20200612112131504](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612112131.png)

返回的结果是把两个数据集中的所有键包含的值分组在一起。