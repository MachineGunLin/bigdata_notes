# 9. Spark Filter函数

在Spark中，Filter函数返回一个新数据集，该数据集是通过选择函数返回`true`的源元素而形成的。因此它仅检索满足给定条件的元素。

#### Filter函数示例

在此示例中，将过滤给定数据并检索**除35之外的所有值**。

在Scala模式下打开Spark:

> $ spark-shell

使用并行化集合创建RDD：

> scala> val data = sc.parallelize(List(10, 20, 35, 40))

读取生成的结果：

> scala> data.collect

![image-20200612092833226](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612092833226.png)

使用过滤器filter函数并传递执行所需的表达式:

> scala> val filterfunc = data.filter(x => x != 35)

读取生成的结果（理论上应该去掉集合中的35）：

> scala> filterfunc.collect

![image-20200612093031124](https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612093031124.png)

确实把集合中的元素35给过滤掉了。